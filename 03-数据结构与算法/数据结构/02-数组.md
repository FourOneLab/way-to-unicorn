---
title: "02 数组"
date: 2020-06-18T18:43:53+08:00
draft: true
---

- [0.1. 如何实现随机访问](#01-如何实现随机访问)
- [0.2. 低效的插入和删除](#02-低效的插入和删除)
  - [0.2.1. 插入操作](#021-插入操作)
  - [0.2.2. 删除操作](#022-删除操作)
  - [0.2.3. 警惕数组的访问越界问题](#023-警惕数组的访问越界问题)
- [0.3. 容器能否完全替代数组](#03-容器能否完全替代数组)

数组不仅是一种编程语言中的数据类型，还是一种最基础的数据结构。

> 在大部分编程语言中，数组都是从 0 开始编号的，但你是否下意识地想过，为什么数组要从 0 开始编号，而不是从 1 开始呢？

从数组存储的内存模型上来看，“下标”最确切的定义应该是“**偏移**(offset)”。如果用 a 来表示数组的首地址，a[0]就是偏移为 0 的位置，也就是首地址，a[k]就表示偏移 k 个 `type_size` 的位置，所以计算 a[k]的内存地址只需要用这个公式：`a[k]_address = base_address + k * type_size`。

但是，如果数组从 1 开始计数，那计算数组元素 a[k]的内存地址就会变为：`a[k]_address = base_address + (k-1)*type_size`。

对比两个公式，不难发现，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。

> 数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。

可能还有历史原因，从C语言使用0作为下标开始，其他语言借鉴了这个设计，如`Python`还是负数下标。

## 0.1. 如何实现随机访问

**数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据**。

- **线性表**（Linear List），就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。链表、队列、栈等也是线性表结构。

![image](/images/b6b71ec46935130dff5c4b62cf273477.jpg)

- **非线性表**，比如二叉树、堆、图等。在非线性表中，数据之间并不是简单的前后关系。

![image](/images/6ebf42641b5f98f912d36f6bf86f6569.jpg)

- **连续的内存空间**和**相同类型的数据**。正是因为这两个限制，有利也有弊：
  - 优势：随机访问
  - 劣势：很多操作变得非常低效，如，删除、插入一个数据（为了保证连续性，就需要做大量的数据搬移工作）

创建一个长度为10的整型数组`a := [10]int{}`，数组内默认十个`0`。如下图所示，计算机给数组`a`，分配了一块连续内存空间 `1000～1039`，其中，内存块的首地址为 `base_address = 1000`。

![image](/images/98df8e702b14096e7ee4a5141260cdc4.jpg)

计算机会给每个内存单元分配一个地址，通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：

```bash
a[i]_address = base_address + i * data_type_size
```

- `data_type_size`：表示数组中每个元素的大小（上面的例子中，存储的是`int`，所以是4个字节）

**数组支持随机访问，根据下标随机访问的时间复杂度是`O(1)`**。

## 0.2. 低效的插入和删除

> 数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效。

### 0.2.1. 插入操作

假设数组的长度为 `n`，如果要将一个数据插入到数组中的第 `k` 个位置。为了把第 `k` 个位置腾出来，给新来的数据，我们需要将第 `k～n` 这部分的元素都顺序地往后挪一位，所以，插入操作的时间复杂度是：

- 最好：O(1)
- 最坏：O(n)
- 平均：O(n)
- 均摊：O(n)

> - 如果数组中的数据是**有序**的，在某个位置插入一个新的元素时，就必须按照上面的方法搬移 `k` 之后的数据。
> - 如果数组中存储的数据**并没有任何规律**，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 `k` 个位置，为了避免大规模的数据搬移，有一个简单的办法就是，直接将第 `k` 位的数据搬移到数组元素的最后，把新的元素直接放入第 `k` 个位置。**利用这种处理技巧，在特定场景下，在第 `k` 个位置插入一个元素的时间复杂度就会降为 `O(1)`**。

### 0.2.2. 删除操作

跟插入数据类似，如果要删除第 `k` 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了，所以删除操作的时间复杂度是：

- 最好：O(1)
- 最坏：O(n)
- 平均：O(n)
- 均摊：O(n)

实际上，在某些特殊场景下，并不一定非得追求数组中数据的连续性。如果将多次删除操作集中在一起执行，删除的效率就会提高不少。

为了避免后续数据会被多次搬移，可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。**JVM 标记清除垃圾回收算法的核心思想**。

### 0.2.3. 警惕数组的访问越界问题

根据语言的不同，数组越界的问题不同，在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。根据前面讲的数组寻址公式，越界的数组访问了不属于数组的内存地址上，得到上个内存地址上保存的值。

> 数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，**访问数组的本质就是访问一段连续内存**，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误，这种情况下，一般都会出现莫名其妙的逻辑错误。

**很多计算机病毒正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统，所以写代码的时候一定要警惕数组越界**。

但并非所有的语言都像 C 一样，把数组越界检查的工作丢给程序员来做，像 Java 本身就会做越界检查，抛出`java.lang.ArrayIndexOutOfBoundsException`。

## 0.3. 容器能否完全替代数组

针对数组类型，很多语言都提供了容器类，比如 Java 中的 `ArrayList`、C++ STL 中的 `vector`。

以Java为例，`ArrayList` 优势：

- 将数组操作的细节封装起来（如插入、删除数据时需要搬移其他数据等）
- 支持动态扩容（存储空间不够时，不需要关心底层的扩容逻辑，会将空间自动扩容为 1.5 倍大小）

> 注意：因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好**在创建 ArrayList 的时候事先指定数据大小**。

也存在一些局限性：

- Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。
- 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。
- 表示多维数组时，用数组往往会更加直观，`Object[][] array`VS`ArrayList<ArrayList<object>>array`。

**对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选**。
