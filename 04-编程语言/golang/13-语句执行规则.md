# 语句执行规则

> Don't communicate by sharing memory; share memory by communicating.
>
> 不要通过共享数据来通讯，以通讯的方式来共享数据。

`channel`类型的值，被用来以通讯的方式共享数据。一般被用来在不同的`goroutine`（代表并发编程模型中的用户级线程）之间传递数据。

## 调度

### 调度时机

- 就绪态 -> 运行态：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；
- 运行态 -> 阻塞态：当进程发生 I/O 事件而阻塞时，操作系统必须另外一个进程运行；
- 运行态 -> 结束态：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；

### 调度原则

- CPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；
- 系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；
- 周转时间：周转时间是进程运行和阻塞时间总和，一个进程的周转时间越小越好；
- 等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；
- 响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。

### 调度算法

- 抢占式
- 非抢占式

#### 单核系统

- 先来先服务调度算法
- 最短作业优先调度算法
- 高响应比优先调度算法
- 时间片轮转调度算法
- 最高优先级调度算法
- 多级反馈队列调度算法

## 并发模型

> 并发模型其实和分布式系统模型非常相似，在并发模型中是线程彼此进行通信，而在分布式系统模型中是 进程 彼此进行通信。然而本质上，进程和线程也非常相似。

- 分布式系统通常要比并发系统面临更多的挑战和问题比如进程通信、网络可能出现异常，或者远程机器挂掉等
- 并发模型同样面临着比如 CPU 故障、网卡出现问题、硬盘出现问题等

### 并行worker

![image](/images/conworker.png)

这些共享状态可能会使用一些工作队列来保存业务数据、数据缓存、数据库的连接池等。

在线程通信中，线程需要确保共享状态是否能够让其他线程共享，而不是仅仅停留在 CPU 缓存中让自己可用，当然这些都是程序员在设计时就需要考虑的问题。

> 多线程在访问共享数据时，会丢失并发性，因为操作系统要保证只有一个线程能够访问数据，这会导致共享数据的争用和抢占。未抢占到资源的线程会**阻塞**。

### 流水线（事件驱动系统）

![image](/images/waterline.png)

#### Actor模型

在 Actor 模型中，每一个 Actor 其实就是一个 Worker， 每一个 Actor 都能够处理任务。

Actor 模型是一个并发模型，它定义了一系列系统组件应该如何动作和交互的通用规则。一个参与者Actor对接收到的消息做出响应，然后可以创建出更多的 Actor 或发送更多的消息，同时准备接收下一条消息。

![image](/images/actor.png)

Actor 模型重在参与交流的实体(即进程)，而 CSP 重在交流的通道，如 Go 中的 channel。

#### Channels模型

> 也叫CSP（Communicating sequential processes）。

在 Channel 模型中，worker 通常不会直接通信，与此相对的，他们通常将事件发送到不同的 通道(Channel)上，然后其他 worker 可以在这些通道上获取消息。

![image](/images/channel.png)

有的时候 worker 不需要明确知道接下来的 worker 是谁，他们只需要将作者写入通道中，监听 Channel 的 worker 可以订阅或者取消订阅，这种方式降低了 worker 和 worker 之间的耦合性。

> 与 Actor 相比，CSP 最大的优点是灵活性。Actor 模型，负责通信的媒介和执行单元是耦合的。而 CSP 中，channel 是第一类对象，可以被独立创造、写入、读出数据，也可以在不同执行单元中传递。
>
> CSP 模型也易受死锁影响，且没有提供直接的并行支持。并行需要建立在并发基础上，引入了不确定性。

CSP 模型不关注发送消息的进程，而是关注发送消息时使用的 channel，而 channel 不像 Actor 模型那样进程与队列紧耦合。而是可以单独创建和读写，并在进程 (goroutine) 之间传递。

## Golang Runtime

### 调度器

Go语言拥有：

- 独特的并发编程模型
- 用户级线程goroutine
- 强大的用于调度goroutine、对接操作系统的调度器

这个调度器是Go语言运行时系统的重要组成部分，主要负责统筹调配Go并发编程模型中的三个主要元素：

- G（goroutine）：用户级线程
- P（processor）：可以承载若干个goroutine，且能够使这些goroutine适时地与系统级线程对接，并得到真正运行的中介
- M（machine）：系统级线程

> 宏观上讲，由于P的存在，用户级线程和系统级线程可以呈现多对多的关系。

例如：

- 当一个正在与某个系统级线程对接并运行的用户级线程，需要因某个事件（等待IO或锁的解除）而暂停运行的时候，调度器总会及时发现，并把这个用户级线程和系统级线程分离，以释放计算资源供其他等待运行的用户级线程使用。
- 当一个用户级线程需要恢复运行的时候，调度器又会尽快为它寻找空闲的计算资源（包括系统级线程）并安排运行。
- 当系统级线程不够用的时候，调度器会帮我们向操作系统申请新的系统级线程。
- 当某一个系统级线程已经无用时，调度器会负责把它及时销毁掉。

**因为调度器帮我们做了很多事，所以Go程序才能高效地利用操作系统和计算机资源**。程序中所有的用户级线程都会被充分地调度，其中的代码也都会并发地运行，即使用户级线程有数十万计。

![image](/images/GPM.png)

![image](/images/go-gpm.png)

- 全局队列（Global Queue）：存放等待运行的G。
- P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建G'时，G'优先加入到P的本地队列，如果队列满了，则会把本地队列中一半的G移动到全局队列。
- P列表：所有的P都在程序启动时创建，并保存在数组中，最多有GOMAXPROCS(可配置)个。
- M：线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M也会尝试从全局队列拿一批G放到P的本地队列，或从其他P的本地队列偷一半放到自己P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复下去。

#### P和M的数量

- P的数量：由启动时环境变量`$GOMAXPROCS`或者是由`runtime`的方法`GOMAXPROCS()`决定。这意味着在程序执行的任意时刻都只有`$GOMAXPROCS`个goroutine在同时运行。
- M的数量:
  - (1) go语言本身的限制：go程序启动时，会设置M的最大数量，默认10000.但是内核很难支持这么多的线程数，所以这个限制可以忽略
  - (2)runtime/debug中的SetMaxThreads函数，设置M的最大数量
  - (3)一个M阻塞了，会创建新的M

### 并发模型

Go 是采用 CSP 的思想的，channel 是 go 在并发编程通信的推荐手段，Go 语言推荐使用通信来进行进程间同步消息。这样做有三点好处:

- 首先，使用发送消息来同步信息相比于直接使用共享内存和互斥锁是一种更高级的抽象，使用更高级的抽象能够为我们在程序设计上提供更好的封装，让程序的逻辑更加清晰；

- 其次，消息发送在解耦方面与共享内存相比也有一定优势，我们可以将线程的职责分成生产者和消费者，并通过消息传递的方式将它们解耦，不需要再依赖共享内存；

- 最后，Go 语言选择消息发送的方式，通过保证同一时间只有一个活跃的线程能够访问数据，能够从设计上天然地避免线程竞争和数据冲突的问题；

#### 并发控制

- `sync.WaitGroup`：某任务需要多 goroutine 协同工作，每个 goroutine 只能做该任务的一部分，只有全部的 goroutine 都完成，任务才算是完成
- `channel+select`：比较优雅的通知一个 goroutine 结束；多groutine中数据传递
- `context`：多层级groutine之间的信号传播（包括元数据传播，取消信号传播、超时控制等），优雅的解决了 goroutine 启动后不可控的问题

## goroutine最佳实践

```go
package main

import "fmt"

func main() {
    for i := 0; i < 10; i++ {
        go func() {
            fmt.Println(i)
        }()
    }
}
```

代码执行后，不会有任何内容输出。

与一个进程总会有一个主线程类似，每一个独立的Go程序运行起来总会有一个主用户线程（goroutine）。**这个主goroutine会在Go程序的运行准备工作完成后被自动地启用**，并不需要任何手动操作。

> 每条go语句一般都会携带一个函数调用，这个被调用的函数被称为go函数，主用户线程（goroutine）的go函数，就是那个程序入口的main函数。

### 已经存在的用户级线程会被优先复用

**go函数被真正执行的时间，总会与其所属的go语句被执行的时间不同**。当程序执行到一条go语句，Go语言运行时系统，会先试图从某个存放空闲的用户级线程的队列中获取某个用户级线程，它只有找不到空闲的用户级线程的情况们才会去创建一个新的用户级线程。

### 用户级线程的创建成本很低

创建一个新的用户级线程并不会像创建一个进程或者一个系统级线程那样，必须通过操作系统的系统调用来完成，在Go语言的运行时系统内部就可以完成了，一个用户级线程就相当于需要并发执行代码片段的上下文环境。

在拿到空闲的用户级线程之后，Go语言运行时系统会用这个用户级线程去包装那个go函数（函数中的代码），然后再把这个用户级线程追加到某个可运行的用户级线程队列（先进先出）中。虽然在队列中被安排运行的时间很快，上述的准备工作也不可避免，因此存在一定时间消耗。**所以go函数的执行时间，总是会明显滞后（相对于CPU和Go程序）于go语句的执行时间**。

**只要go语句本身执行完毕，Go程序完全不用等待go函数的执行，它会立刻去执行后面的语句，这就是异步并发执行**。

> 注意：一旦主用户级线程（main函数中的那些代码）执行完毕，当前的Go程序就会结束运行。如果在Go程序结束的那一刻，还有用户级线程没有运行，那就没有机会运行了。

严格的说，Go语言并不会保证用户级线程会以怎样的顺序运行，因为主用户级线程会与手动启动的其他用户级线程一起接受调度，又因为调度器很可能会在用户级线程中的代码只执行了一部分的时候暂停，以期所有的用户级线程有更公平的运行机会。所以哪个用户级线程先执行完，是不可预知的，除非使用了某种Go语言提供的方式进行人为干预。

## 主用户级线程等待其他用户级线程

1. 让主用户级线程`Sleep()`一会：但是时间难以把握
2. 其他用户级线程运行完毕之后发出通知：创建一个通道，长度与手动启动的用户级线程一致，每个用户级线程运行完毕的时候向通道中发送一个值（在go函数的最后发送），在main函数的最后接收通道中的值，接收次数与手动启动的用户级线程数量一直
3. sync包中的`sync.WaitGroup`类型

```go
sign := make(chan struct{}, num)        // 结构体类型的通道

sign <- struct{}{}

<- sign
```

`struct{}`类似于空接口`interface{}`，代表既不包含任何字段也不拥有任何方法的空结构体类型。

**`struct{}`类型的值的表示方法只有一个:`struct{}{}`，它占用的内存空间是0字节。这个值在整个Go程序中永远都只会存在一份**。无数次的试用这个值的字面量，但是用到的却是同一个值。

## 用户级线程按顺序执行

```go
package main

import (
            "fmt"
            "sync/atomic"
            "time"
        )

func main() {
    // 用户级线程随机执行
    for i := 0; i < 10; i++ {
        go func() {
            fmt.Println(i)
        }()
    }

    // 用户级线程按顺序执行
    for i := 0; i < 10; i++ {
        go func(i int) {            // 让go函数接收一个int型参数，在调用它的时候，把变量传进去
            fmt.Println(i)          // 这样Go语言包装每个用户级线程都可以拿到一个唯一的整数
        }(i)
    }

    // 在go语句被执行时，传给go函数的参数`i`会被先求值，如此就得到了当次迭代的序号，
    // 之后，无论go函数会在什么时候执行，这个参数值都不会变，
    // 也就是go函数中调用`fmt.Prinrln`函数打印的一定是那个当次迭代的序号。

    var count uint32

    for i := uint32(0); i < 10; i++ {
        go func(i uint32) {
            fn := func() {
                fmt.Println(i)
            }
            trigger(i, fn)
        }(i)
    }

    trigger := func(i uint32, fn func()) {
        for {
            if n := atomic.LoadUint32(&count); n == i {     // 原子操作
                fn()
                atomic.AddUint32(&count, 1)                 // 原子操作
                break
            }
            time.Sleep(time.Nanosecond)
        }
    }

    trigger(10, func(){})
}
```

## 系统调用

Go 会优化系统调用（无论阻塞与否），通过运行时封装它们。封装的那一层会把 `P` 和线程 `M` 分离，并且可以让另一个用户线程在它上面运行。下面以文件读取举例：

```go
func main() {
   buf := make([]byte, 0, 2)

   fd, _ := os.Open("number.txt")
   fd.Read(buf)
   fd.Close()

   println(string(buf)) // 42
}
```

文件读取的流程如下：

![image](/images/read-file.png)

`P0` 现在在空闲 list 中，有可能被唤醒。当系统调用 exit 时，Go 会遵守下面的规则，直到有一个命中了。

- 尝试去捕获相同的 P，在我们的例子中就是 P0，然后 resume 执行过程
- 尝试从空闲 list 中捕获一个 P，然后 resume 执行过程
- 把 G 放到全局队列里，把与之相关联的 M 放回空闲 list 去

然而，在像 http 请求等 non-blocking I/O 情形下，Go 在资源没有准备好时也会处理请求。在这种情形下，第一个系统调用 — 遵循上述流程图 — 由于资源还没有准备好所以不会成功，（这样就）迫使 Go 使用 network poller 并使协程停驻，如下示例。

```go
func main() {
   http.Get(`https://httpstat.us/200`)
}
```

当第一个系统调用完成且显式地声明了资源还没有准备好，G 会在 network poller 通知它资源准备就绪之前一直处于停驻状态。在这种情形下，线程 M 不会阻塞：

![image](/images/non-blocking.png)

在 Go 调度器在等待信息时 G 会再次运行。调度器在获取到等待的信息后会询问 network poller 是否有 G 在等待被运行。

![image](/images/syscall.png)

如果多个协程都准备好了，只有一个会被运行，其他的会被加到全局的可运行队列中，以备后续的调度。

## 系统线程方面的限制

在系统调用中，Go 不会限制可阻塞的 OS 线程数。

> `GOMAXPROCS` 变量表示可同时运行用户级线程的操作系统线程的最大数量。系统调用中可被阻塞的最大线程数并没有限制；可被阻塞的线程数对 `GOMAXPROCS` 没有影响。这个包的 `GOMAXPROCS` 函数查询和修改这个最大数限制。

如下示例：

```go
func main() {
   var wg sync.WaitGroup

   for i := 0;i < 100 ;i++  {
      wg.Add(1)

      go func() {
         http.Get(`https://httpstat.us/200?sleep=10000`)

         wg.Done()
      }()
   }

   wg.Wait()
}
```

利用追踪工具得到的线程数如下：

![image](/images/threads.png)

由于 Go 优化了系统线程使用，所以当 G 阻塞时，它仍可复用，这就解释了为什么图中的数跟示例代码循环中的数不一致。
